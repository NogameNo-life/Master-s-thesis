\chapter{Применение нейросетевых моделей для генерации ограничений в планировщике и разработка пользовательского интерфейса}
\label{ch:chapter4}

Современные методы оптимизации производства всё чаще дополняются подходами искусственного интеллекта, включая использование нейронных сетей. В рамках данной работы была реализована система, в которой генерация ограничений для планировщика осуществляется с помощью языковых моделей (LLM), обрабатывающих текстовые описания ограничений (промпты). Для удобства взаимодействия с системой был разработан специализированный веб-интерфейс на базе React и Next.js.

\section{Обзор используемых моделей }

Генерация ограничений является одной из ключевых задач в системах автоматизированного планирования и оптимизации, таких как Timefold Solver. В этих системах ограничения традиционно описываются с помощью специализированных API, например Constraint Streams на Java или Kotlin. Однако ручное написание таких ограничений требует глубоких знаний предметной области и технических деталей, что часто замедляет разработку и увеличивает риск ошибок.

Современные достижения в области больших языковых моделей (LLM) открывают новые перспективы для автоматизации этого процесса. Использование нейросетей позволяет переводить текстовое описание ограничений на естественном языке в формальный программный код, тем самым снижая порог входа для специалистов и ускоряя создание эффективных решений. В данном разделе рассматриваются две ключевые модели, применяемые в вашей системе: модель машинного перевода Optus-ru-en и модель генерации кода codegen-2B-multi.

Модель \textbf{Optus-ru-en} представляет собой специализированную систему нейросетевого перевода с русского на английский язык, оптимизированную именно под технические и профильные тексты. Эта модель построена на архитектуре трансформера с механизмами многоголового внимания, что обеспечивает высокое качество семантической передачи при сохранении точности терминологии. Особое внимание при обучении уделялось корпусам с технической лексикой, что позволяет модели адекватно обрабатывать описания ограничений и бизнес-правил, минимизируя искажения смысла и двусмысленность. Благодаря среднему размеру и оптимизациям, Optus-ru-en может работать как локально, так и в облачной среде с минимальными задержками, что делает её удобной для интеграции в конвейер генерации кода.

Следующим этапом после перевода является генерация кода на Java — языке, используемом в Timefold Solver. Для этой задачи применяется модель \textbf{codegen-2B-multi} — представитель семейства CodeGen, разработанный компанией Salesforce Research. Она основана на архитектуре трансформера и содержит около 2 миллиардов параметров, что обеспечивает баланс между качеством генерации и вычислительными требованиями. Модель обучалась на обширных мульти-язычных датасетах исходного кода из открытых репозиториев, что позволяет ей эффективно генерировать корректный синтаксически и семантически код на различных языках программирования, включая Java и Kotlin.

Важной особенностью codegen-2B-multi является её способность учитывать контекст задачи благодаря обучению на параллельных данных — сочетании кода и комментариев. Это даёт модели возможность связывать описания требований с соответствующими программными конструкциями, создавая целостные методы, классы и даже целые программные модули. Кроме того, благодаря умеренному размеру, модель может запускаться на современных GPU без чрезмерных затрат ресурсов, что критично для локального использования и обеспечения конфиденциальности данных.

Синергия этих двух моделей в вашей системе реализуется в виде конвейера обработки: на первом этапе исходный русский текст описания ограничения переводится с помощью Optus-ru-en на английский язык, максимально сохраняя технические детали и терминологию. Затем полученный английский текст поступает на вход модели codegen-2B-multi, которая генерирует корректный и структурированный Java-код ограничений. Такой подход не только снижает требования к знанию английского языка у конечных пользователей, но и значительно ускоряет процесс разработки сложных ограничений.

Тем не менее, использование этих моделей требует осознания их ограничений. Optus-ru-en, несмотря на оптимизацию под технический стиль, может испытывать сложности с редкими или сильно специфичными терминами, что иногда приводит к потере нюансов контекста. Аналогично, codegen-2B-multi порой создаёт избыточный или общий код, который нуждается в постобработке и верификации, особенно при работе с очень специфичными бизнес-правилами.

В целом, интеграция моделей Optus-ru-en и codegen-2B-multi в рамках единой системы даёт мощный инструмент для автоматической генерации ограничений в Timefold Solver. Это позволяет снизить трудозатраты на разработку, улучшить качество и консистентность кода, а также поддерживать гибкость и масштабируемость решения за счёт возможности локального запуска и дальнейшего дообучения моделей под специфические задачи предприятия.

\section{Архитектура seq2seq: энкодер-декодер}

Модели seq2seq (sequence-to-sequence) представляют собой класс нейросетевых архитектур, которые решают задачу преобразования одной последовательности в другую. Классическим примером является машинный перевод, где входной текст на одном языке преобразуется в текст на другом языке. Основная идея заключается в том, чтобы сначала закодировать всю исходную последовательность в некоторую компактную форму — контекстное представление, а затем на основе этого представления сгенерировать выходную последовательность.

Архитектурно модели seq2seq состоят из двух ключевых компонентов: энкодера и декодера. Энкодер принимает на вход исходную последовательность, например, предложение на русском языке, и последовательно обрабатывает каждый элемент этой последовательности, преобразуя её в набор контекстных векторов, содержащих информацию о всей последовательности. Декодер, в свою очередь, получает это представление и шаг за шагом генерирует выходную последовательность, например, перевод на английский язык.

Перед тем как подать входные данные в энкодер, текстовые последовательности необходимо перевести из формата строк в числовой вид, подходящий для обработки нейросетью. Для этого применяется слой Embedding, который преобразует каждый токен (слово или подслово) во входной последовательности в вектор фиксированной размерности. Такой вектор можно рассматривать как точку в многомерном пространстве признаков, где близкие по смыслу слова располагаются рядом. Например, слово «milk» может быть преобразовано в вектор размерности 300, представляющий его семантическое значение.\cite{habrseq2seq}

Основу энкодера обычно составляют рекуррентные нейросети (RNN), чаще всего реализованные с использованием специальных механизмов — LSTM (Long Short-Term Memory) или GRU (Gated Recurrent Unit). Эти сети последовательно обрабатывают входные данные: на каждом временном шаге RNN получает эмбеддинговое представление текущего токена и скрытое состояние, переданное с предыдущего шага. Выходом каждого шага является новое скрытое состояние, которое несет информацию обо всей последовательности на данный момент и используется для обработки следующего токена.

После того как весь вход обработан, последний скрытый вектор энкодера становится так называемым контекстным вектором. Это сжатое представление всей исходной последовательности, которое содержит ключевую смысловую информацию и передается декодеру для генерации выхода. Именно этот вектор помогает модели понять, о чём был входной текст, и сформировать правильный ответ.

Для повышения качества кодирования часто применяются двунаправленные RNN. В таких архитектурах две рекуррентные сети обрабатывают вход одновременно, одна — слева направо, другая — справа налево. Их выходные состояния объединяются на каждом шаге, что позволяет учитывать контекст как с левой, так и с правой стороны для каждого токена. Такой подход существенно улучшает понимание контекста, особенно в длинных предложениях.

Пример из практики: если на вход подаётся фраза «Если продукт содержит орехи, фасовать его отдельно.», энкодер формирует скрытое представление, отражающее смысл этой фразы. Декодер затем с помощью этого представления генерирует эквивалентный английский текст — «If the product contains nuts, pack it separately.»

Среди преимуществ архитектуры энкодер-декодер можно выделить её универсальность: она хорошо подходит для задач, где вход и выход могут иметь разную длину и структуру. Полный анализ входной последовательности перед генерацией позволяет использовать глобальный контекст, что особенно важно для перевода и суммаризации текста. Вместе с тем, архитектура обладает и недостатками. Во-первых, модели могут быть достаточно громоздкими и ресурсоёмкими, особенно при увеличении размеров слоёв энкодера и декодера. Во-вторых, обучение и развёртывание таких моделей требуют значительных вычислительных ресурсов и времени.

Энкодеры широко применяются в современных системах машинного перевода, например, в моделях Helsinki-NLP, T5 и mBART, а также в задачах суммаризации и ответа на вопросы.

С другой стороны, существует архитектура, построенная только на декодере — так называемые decoder-only модели. В таких моделях отсутствует отдельный энкодер. Вместо этого модель обучается предсказывать следующий токен на основе всех предыдущих. Вход подаётся в виде единого промпта — последовательности токенов, и модель генерирует ответ, предсказывая токены по одному. Такая архитектура особенно эффективна в задачах генерации текста, программного кода, автодополнения и интерактивного общения.

Например, если подать в модель запрос: «If two jobs have different allergens, insert a cleaning job between them.» — модель сгенерирует соответствующий код:

\begin{lstlisting}[caption={Промпт}, label={lst:prompt_example}]
If two jobs have different allergens, insert a cleaning job between them.
\end{lstlisting}

\begin{lstlisting}[caption={Ответ, который модель может сгенерировать}, label={lst:model-answer}]
if (!Objects.equals(jobA.getProduct().getAllergen(), jobB.getProduct().getAllergen())) {
// insert cleaning job
}
\end{lstlisting}

Преимущества decoder-only архитектуры заключаются в её простоте и эффективности при генерации длинных последовательностей. Такая модель не разделена на энкодер и декодер, что упрощает её структуру и ускоряет обучение и вывод. Её можно гибко использовать в самых разных сценариях: от чатов и автодополнения до создания сложных программных модулей и документации.

Однако у decoder-only моделей есть и ограничения. Они менее устойчивы к потере контекста при генерации больших объёмов текста и могут «забывать» или искажать начальные условия, особенно если промпт слишком длинный. В сравнении с seq2seq они не так глубоко «понимают» смысл входного текста, что особенно критично в задачах перевода и преобразования, требующих точного сохранения смысла.

Архитектурно декодер во многих аспектах похож на энкодер, поскольку оба используют схожие механизмы, такие как самовнимание (self-attention). Однако задачи у них разные: энкодер «понимает» вход, а декодер «генерирует» выход. Архитектуры decoder-only применяются в моделях для программирования и генерации кода, таких как GPT-Neo, StarCoder и CodeGen, а также в автодополнении кода и генерации технических текстов.



\begin{table}[h]
\centering
\caption{Сравненение Seq2seq (Encoder-Decoder) с Decoder-only}
\begin{tabularx}{\textwidth}{|p{4cm}|p{4cm}|X|}
\hline
\textbf{Характеристика}         & \textbf{Seq2seq (Encoder-Decoder)} & \textbf{Decoder-only} \\
\hline
Основное применение             & Перевод, суммаризация & Генерация текста, кода \\
\hline
Компоненты                       & Энкодер + Декодер  & Только декодер \\
\hline
Пример модели                    & OPUS-MT, T5 & GPT, StarCoder, CodeGen \\
\hline
Контекст                         & Полный вход анализируется заранее & Генерация по мере поступления \\
\hline
Поддержка переменной длины входа & Да & Да \\
\hline
 Качество перевода               & Высокое & Ограниченное \\
\hline
 Способность к автодополнению    & Средняя & Очень высокая \\
\hline
 Эффективность на больших входах & Ниже & Выше \\
\hline
 Расход памяти                   & Выше & Ниже \\
\hline
 Универсальность                 & Шире & Уже \\
\hline
\end{tabularx}
\label{table:compareModels}
\end{table}

В контексте разработки ИИ-системы для генерации Constraint Streams обе архитектуры дополняют друг друга. Seq2seq-модель (например, OPUS-MT) берёт на себя задачу точного и контекстно корректного перевода технических требований с русского на английский язык, сохраняя глубокую семантику. Далее decoder-only модели (CodeGen, StarCoder) на основе английского описания создают корректный, логичный Java-код, выполняя роль генератора.

Такое разделение задач позволяет добиться высокого качества результата: модель seq2seq отвечает за «понимание» и качественную интерпретацию входных данных, а decoder-only модель — за эффективное «исполнение» и генерацию рабочего кода.

Стоит отметить, что seq2seq архитектура более мощная и точная для задач трансформации одного языка в другой, так как она отдельно анализирует всю входную последовательность перед генерацией. Однако её недостатком является более высокая вычислительная сложность и замедленное декодирование, так как генерация происходит токен за токеном, и чем длиннее выходная последовательность, тем медленнее процесс. При этом авторегрессивные модели склонны к повторениям и пропускам, что требует использования дополнительных методов, например, лучевого поиска (beam search), который улучшает качество, но увеличивает время вычислений.
\section{Архитектура разработанной системы}

Разрабатываемая система представляет собой распределённое приложение, состоящее из трёх основных компонентов, упакованных в отдельные Docker-контейнеры и объединённых в единую среду с помощью \texttt{docker-compose}. Все компоненты развернуты локально на сервере с GPU, что позволяет эффективно использовать аппаратное ускорение для нейросетевых моделей.

\begin{enumerate}
    \item \textbf{Веб-интерфейс (Next.js)} — предоставляет пользователю удобный графический интерфейс с тремя формами для взаимодействия:
    \begin{itemize}
        \item Ввод текста на русском языке;
        \item Отправка текста на сервис перевода;
        \item Отправка переведённого текста на сервис генерации кода;
        \item Отображение результатов перевода и сгенерированного кода;
        \item Управление историей запросов.
    \end{itemize}

    Веб-интерфейс реализован с использованием фреймворка \texttt{Next.js} и библиотеки \texttt{React}, что обеспечивает серверный рендеринг и высокую производительность. Для стилизации используется \texttt{Tailwind CSS}.

    \item \textbf{Сервис перевода (Translator)} — контейнер с REST API, реализованным на \texttt{FastAPI}. В нём развернута нейросетевая модель перевода (например, Helsinki-NLP/opus-mt-ru-en или аналогичная), загруженная локально и использующая библиотеку \texttt{transformers} от Hugging Face. Сервис принимает русский текст, выполняет его перевод на английский и возвращает результат.

    \item \textbf{Сервис генерации кода (Codegen)} — также контейнер с REST API на \texttt{FastAPI}, в котором локально размещена модель для генерации Java-кода на основе английского промпта (например, CodeLlama или CodeGen). Получив на вход переведённый текст, сервис возвращает сгенерированный код с Constraint Streams для Timefold Solver.

\end{enumerate}

Все три компонента запускаются и управляются с помощью \texttt{docker-compose.yml}, который описывает сеть, порты и зависимости между контейнерами. Это упрощает развертывание и масштабирование системы.

\bigskip

\textbf{Основные технологические детали:}

\textbf{Docker и Docker Compose:}  
Docker — это платформа контейнеризации, которая позволяет упаковывать приложения вместе со всеми необходимыми зависимостями и конфигурациями в изолированные, легковесные контейнеры. Такой подход гарантирует, что приложение будет работать одинаково на любой машине, будь то локальный компьютер разработчика, тестовый сервер или производственный кластер. Контейнеры обеспечивают быструю и предсказуемую доставку, упрощают масштабирование и управление обновлениями.  
Docker Compose — инструмент, который позволяет описывать и запускать многоконтейнерные Docker-приложения с помощью единого файла конфигурации (docker-compose.yml). В нём можно определить сервисы, их образы, сетевые связи, переменные окружения и тома. Это значительно упрощает управление сложной системой из нескольких взаимосвязанных компонентов, как в нашем случае: веб-интерфейс, сервис перевода и сервис генерации кода.

\textbf{FastAPI:}  
FastAPI — современный веб-фреймворк на Python, ориентированный на высокую производительность и удобство разработки RESTful API. Он построен на асинхронной модели ввода-вывода с использованием asyncio, что позволяет эффективно обрабатывать большое количество одновременных запросов без блокировок.  
FastAPI обеспечивает быструю генерацию OpenAPI спецификаций, поддержку валидации данных с помощью Pydantic, автодокументацию API через Swagger и ReDoc, что облегчает тестирование и интеграцию. Благодаря этим качествам FastAPI идеально подходит для разработки сервисов, обрабатывающих запросы к нейросетям и требующих низкой задержки ответа.

\textbf{Hugging Face Transformers:}  
Библиотека Hugging Face Transformers предоставляет доступ к множеству предобученных моделей обработки естественного языка (NLP), таких как BERT, GPT, MarianMT и многих других. В нашем проекте она используется для перевода текста с русского на английский, опираясь на мощные трансформерные архитектуры.  
Данная библиотека поддерживает загрузку и инференс моделей как локально, так и через облачные API, что обеспечивает гибкость в развертывании. Благодаря ей достигается высокая точность перевода и возможность кастомизации под задачи пользователя.

\textbf{Next.js и React:}  
Next.js — это фреймворк для React, предоставляющий серверный рендеринг (SSR), статическую генерацию страниц (SSG) и маршрутизацию «из коробки». Эти возможности позволяют создавать быстро загружаемые и SEO-оптимизированные веб-приложения с плавной интерактивностью.  
React — библиотека для создания пользовательских интерфейсов, основанная на компонентном подходе и виртуальном DOM, что ускоряет обновление страницы и улучшает UX.  
В нашем проекте Next.js отвечает за отображение форм для ввода текста, отображение перевода и сгенерированного кода, а также обработку событий, таких как нажатие кнопки «Перевести» или «Сгенерировать код», инициирующих взаимодействие с backend-сервисами.

\textbf{GPU-сервер:}  
Использование локального сервера с GPU позволяет значительно повысить производительность нейросетевых моделей. Графические процессоры (GPU) оптимизированы для параллельных вычислений, что критично для задач глубокого обучения, включая трансформеры и другие архитектуры нейросетей.  
Развёртывание моделей на GPU-сервере обеспечивает низкую задержку при обработке запросов, что особенно важно для интерактивных приложений, где пользователю требуется оперативный ответ. Также локальное хранение моделей повышает безопасность и конфиденциальность данных, исключая передачу чувствительной информации через интернет.

\bigskip

\textbf{Последовательность работы системы:}
\begin{enumerate}
    \item Пользователь вводит текст на русском языке в веб-интерфейсе.
    \item Веб-приложение отправляет запрос на сервис перевода через локальную сеть Docker.
    \item Сервис перевода возвращает английский текст.
    \item Веб-приложение отображает перевод и при нажатии кнопки «Генерировать код» отправляет английский текст на сервис генерации кода.
    \item Сервис генерации возвращает сгенерированный Java-код.
    \item Веб-интерфейс отображает результат пользователю и сохраняет историю взаимодействий.
\end{enumerate}

Такой модульный подход обеспечивает удобство поддержки и возможности масштабирования, а также гибкость в замене отдельных компонентов (например, обновление модели генерации кода или переводчика).

\bigskip

\textbf{Схема архитектуры (пример):}

\begin{center}
\begin{tikzpicture}[node distance=1.5cm and 1cm]

% Определяем узлы (в правильном порядке)
\node (user) [user] {Пользователь};
\node (web) [web, right=3cm of user] {Веб-интерфейс (Next.js)};

\node (server) [server, below=1.5cm of $(user)!0.5!(web)$, minimum height=5.5cm, anchor=north] {Сервер с GPU};

% Docker сервисы внутри сервера
\node (proxy) [docker, fill=green!20, below left=0.3cm and -1.5cm of server.north] {Контейнер: proxy (Next.js)};
\node (translator) [docker, fill=orange!20, below=0.5cm of proxy] {Контейнер: translator (переводчик)};
\node (codegen) [docker, fill=orange!20, below=0.5cm of translator] {Контейнер: codegen (генератор кода)};

% Сначала рисуем стрелки (все)
\draw [arrow] (user) -- (web);
\draw [arrow] (web) -- (proxy);
\draw [arrow] (proxy) -- (translator);
\draw [arrow] (proxy) -- (codegen);

% Затем повторно рисуем узлы proxy, translator, codegen, чтобы стрелки частично закрылись
\node[block, fill=green!20, rounded corners=5pt, minimum height=1.2cm, minimum width=3.8cm, text centered, font=\small] (proxy2) at (proxy) {Контейнер: proxy (Next.js)};
\node[block, fill=orange!20, rounded corners=5pt, minimum height=1.2cm, minimum width=3.8cm, text centered, font=\small] (translator2) at (translator) {Контейнер: translator (переводчик)};
\node[block, fill=orange!20, rounded corners=5pt, minimum height=1.2cm, minimum width=3.8cm, text centered, font=\small] (codegen2) at (codegen) {Контейнер: codegen (генератор кода)};

\coordinate (labelPos) at ($(proxy)!0.75!(codegen)$);
% Подписи к стрелкам с аккуратным позиционированием и смещением
\node at ($(web)!0.5!(proxy)$) [above left, font=\tiny] {запрос перевода};
\node at ($(proxy)!0.5!(translator)$) [left, font=\tiny] {перевод};
\node at (labelPos) [right, font=\tiny, xshift=4pt, yshift=0pt] {генерация кода};


\end{tikzpicture}
\end{center}


\section{Преимущества и ограничения подхода}

\subsection{Преимущества}

Одним из ключевых достоинств предлагаемого подхода является значительное ускорение процесса разработки ограничений для планировщика. Благодаря использованию генерации кода на основе естественного языка, специалисты могут формулировать описания ограничений в привычной текстовой форме, а система самостоятельно преобразует их в корректный Java-код с использованием Constraint Streams библиотеки Timefold Solver. Это позволяет существенно сократить время, необходимое для ручной имплементации, особенно в случаях, когда модель содержит большое количество разнообразных условий.

Данный подход особенно полезен для пользователей, не обладающих глубокими знаниями в области программирования на Java. За счёт применения встроенного модуля перевода, текст на русском языке автоматически преобразуется в английский, после чего подаётся на вход модели генерации кода. Это позволяет значительно расширить круг потенциальных пользователей, снизить барьер входа в технологию и уменьшить количество синтаксических и логических ошибок, возникающих при ручной разработке ограничений.

Дополнительным преимуществом является высокая гибкость. Пользователь может изменять формулировки ограничений в интерфейсе, получать различные версии их программной реализации и выбирать наиболее подходящую. Такая возможность проведения быстрой итерации особенно ценна на этапах прототипирования и экспериментального подбора весов, когда требуется тестировать множество комбинаций ограничений и оценивать их влияние на итоговое расписание.

Важным архитектурным решением является локальное развертывание всех компонентов системы с поддержкой графических ускорителей (GPU). Это обеспечивает полный контроль над процессом генерации и защиту корпоративных данных, поскольку все модели и исходные тексты обрабатываются внутри изолированного контура — без отправки запросов в облако. Такой подход особенно важен в производственной среде, где конфиденциальность технологической информации имеет критически важное значение.

Наконец, модульная архитектура системы, построенная с использованием Docker и Docker Compose, обеспечивает удобство развертывания, масштабирования и обновления. Каждый компонент системы — переводчик, генератор кода и пользовательский интерфейс — разрабатывается и поддерживается независимо. Это упрощает сопровождение, повторное использование и адаптацию системы к различным сценариям и типам задач.

\subsection{Ограничения}

Несмотря на все преимущества, предложенный подход имеет ряд ограничений, которые необходимо учитывать при его практическом применении.

Прежде всего, автоматически сгенерированный код требует обязательной валидации со стороны эксперта. Хотя модель может генерировать синтаксически корректные Constraint Streams, логика ограничения может не соответствовать ожиданиям пользователя или содержать неявные ошибки. Особенно это критично в системах, где планировщик принимает решения, влияющие на производственные или финансовые показатели предприятия. Следовательно, результат генерации всегда должен быть просмотрен и, при необходимости, откорректирован вручную.

Кроме того, качество конечного Java-кода во многом зависит от корректности перевода входного описания. Переводчик, основанный на нейросети, может допускать смысловые и грамматические искажения, особенно при использовании сложных синтаксических конструкций или терминологии. Это, в свою очередь, может привести к неправильной интерпретации запроса генератором и, как следствие, к созданию некорректного кода. Аналогичная проблема касается самой модели генерации кода — при неоднозначных или недостаточно структурированных запросах результат может оказаться неполным или слишком общим.

Существенным ограничением также является ограниченное понимание бизнес-контекста со стороны нейросетевых моделей. Модели обучены на обширных наборах данных, но при этом не обладают встроенным знанием конкретной предметной области. Поэтому при отсутствии точного и подробного описания задачи, модель может не учесть важные технологические нюансы или предложить обобщённое решение, не применимое в конкретной производственной ситуации.

Следующее ограничение связано с качеством входных данных. Эффективность всей системы напрямую зависит от ясности и точности формулировок, введённых пользователем. Нечёткие или неполные описания могут приводить к искажениям на этапе перевода и к неинформативному результату генерации. Таким образом, пользователь всё равно должен обладать базовыми знаниями предметной области и внимательностью при формулировке запросов.

Наконец, развёртывание моделей с поддержкой GPU требует наличия соответствующей вычислительной инфраструктуры, а также определённых навыков для настройки и сопровождения программной среды. Запуск даже небольших моделей генерации кода требует значительных ресурсов оперативной памяти и графического ускорителя, что может быть затруднительно для небольших компаний или в условиях ограниченного бюджета.

Таким образом, хотя предложенный подход и представляет собой мощный инструмент автоматизации и ускорения процесса разработки ограничений, он требует внимательной настройки, квалифицированного сопровождения и чётко сформулированных запросов для достижения высокой точности и надёжности результата.



